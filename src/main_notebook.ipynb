{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "from db_queries import username, password, dsn, dbhostname, service_name, dbtables, querys\n",
    "from table_functions import *\n",
    "from analyze_visualisation import *\n",
    "from decision_tree import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "try:\n",
    "    sqlalchemy_engine=\"oracle+cx_oracle://\"+username+\":\"+password+\"@\"+dbhostname+\"/?service_name=\"+service_name\n",
    "    engine = sqlalchemy.create_engine(sqlalchemy_engine, arraysize=1000)\n",
    "    for table, query in zip(dbtables, querys):\n",
    "        data.update({table: pd.read_sql(query, engine)})\n",
    "except SQLAlchemyError as e:\n",
    "    print(e)\n",
    "\n",
    "data = drop_unused_columns(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table = combine_final_table(data)\n",
    "final_table = create_final_status(final_table)\n",
    "final_table = drop_columns_not_used_in_ml(final_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table, categorized_columns = categorize_data(final_table)\n",
    "save_df_to_csv(final_table, 'final_table_before_standarization.csv')\n",
    "final_table = standarize_data(final_table)\n",
    "save_df_to_csv(final_table, 'final_table_before_normalization.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table = read_csv('final_table_before_normalization.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorized_columns.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = split_data(final_table)\n",
    "for name in ['x_train', 'x_valid', 'x_test']:\n",
    "    ml_data[f'{name}'].drop(columns=categorized_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorized_columns = list(ml_data['x_train'].iloc[:, 130:].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data['x_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data['x_train'], scaler = normalize_data(ml_data['x_train'], categorized_columns)\n",
    "save_df_to_csv(ml_data['x_train'], 'x_train.csv')\n",
    "save_df_to_csv(ml_data['y_train'], 'y_train.csv')\n",
    "ml_data['x_valid'] = normalize_data(ml_data['x_valid'], categorized_columns, scaler)\n",
    "save_df_to_csv(ml_data['x_valid'], 'x_valid.csv')\n",
    "save_df_to_csv(ml_data['y_valid'], 'y_valid.csv')\n",
    "ml_data['x_test'] = normalize_data(ml_data['x_test'], categorized_columns, scaler)\n",
    "save_df_to_csv(ml_data['x_test'], 'x_test.csv')\n",
    "save_df_to_csv(ml_data['y_test'], 'y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_data(final_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table_9, final_table_10 = distinct_machine(final_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drzewa decyzyjne\n",
    "\n",
    "clf = create_decision_tree_model(ml_data['x_train'], ml_data['y_train'])\n",
    "print_decision_tree_stats(clf, ml_data['x_test'], ml_data['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# las losowy\n",
    "\n",
    "clf = RandomForestClassifier(bootstrap=True, max_depth=100, max_features=3, min_samples_leaf=4, min_samples_split=8, n_estimators=300)\n",
    "clf.fit(ml_data['x_train'], ml_data['y_train'])\n",
    "y_pred = clf.predict(ml_data['x_test'])\n",
    "print(classification_report(ml_data['y_test'], y_pred))\n",
    "print(confusion_matrix(ml_data['y_test'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "\n",
    "clf = XGBClassifier()\n",
    "clf.fit(ml_data['x_train'], ml_data['y_train'])\n",
    "y_pred = clf.predict(ml_data['x_test'])\n",
    "print(classification_report(ml_data['y_test'], y_pred))\n",
    "print(confusion_matrix(ml_data['y_test'], y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
