{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "from ml_functions import *\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from db_queries import username, password, dsn, dbhostname, service_name, dbtables, querys\n",
    "from table_functions import *\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import xgboost as xgb\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_october = load_csv('test_data_from_october.csv')\n",
    "whole_table_with_all_columns = load_csv('final_whole_table.csv')\n",
    "from_october_new_status = load_csv('test_data_from_october_new_status.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from last id functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DGM id - oni id_dmc\n",
    "# DGM dmc - MEB_DMC dmc_casting\n",
    "\n",
    "def read_last_meb_dgm(last_id = 0):\n",
    "\n",
    "    data = {}\n",
    "    if last_id:\n",
    "        query = f\"\"\"SELECT *\n",
    "            FROM (\n",
    "                SELECT\n",
    "                    t.*,\n",
    "                    ROW_NUMBER() OVER (PARTITION BY DMC ORDER BY ID DESC) AS rn\n",
    "                FROM\n",
    "                    Z3DMC.MEB_DGM t\n",
    "            ) subquery\n",
    "            WHERE rn = 1\n",
    "            AND id > {last_id}\"\"\"\n",
    "\n",
    "    else:\n",
    "        query = \"\"\"SELECT *\n",
    "            FROM (\n",
    "                SELECT *\n",
    "                FROM Z3DMC.MEB_DGM\n",
    "                ORDER BY ID DESC\n",
    "            )\n",
    "            WHERE ROWNUM = 1\n",
    "            \"\"\"\n",
    "    \n",
    "    try:\n",
    "        sqlalchemy_engine=\"oracle+cx_oracle://\"+username+\":\"+password+\"@\"+dbhostname+\"/?service_name=\"+service_name\n",
    "        engine = sqlalchemy.create_engine(sqlalchemy_engine, arraysize=1000)\n",
    "        data.update({'MEB_DGM': pd.read_sql(query, engine)})\n",
    "    except SQLAlchemyError as e:\n",
    "        print(e)\n",
    "    \n",
    "    data['MEB_DGM'].drop(columns=['timestamp','data_znakowania','data_odlania', 'metal_level', 'metal_pressure', 'max_press_kolbenhub', 'oni_temp_curr_f2'], inplace= True)\n",
    "\n",
    "    last_id = data['MEB_DGM'].id.max()\n",
    "    \n",
    "    return data, last_id\n",
    "\n",
    "def check_if_meb_base(data):\n",
    "    size0 = data['MEB_DGM'].shape[0]\n",
    "    data['MEB_DGM'].dmc = data['MEB_DGM']['dmc'].str.strip()\n",
    "    data['MEB_DGM'] = data['MEB_DGM'][(data['MEB_DGM']['nr_dgm'].between(8, 10)) & (data['MEB_DGM']['dmc'].apply(lambda x: len(str(x)) == 21))]\n",
    "    size1 = data['MEB_DGM'].shape[0]\n",
    "    if data['MEB_DGM'].empty:\n",
    "        print('There are not MEB_BASE+ part produced since last time')\n",
    "        return 1\n",
    "    else:\n",
    "        print(f\"{size1} of {size0} are MEB Base+ parts\")\n",
    "        return data\n",
    "\n",
    "def read_oni(data):\n",
    "    id_list = list(data['MEB_DGM'].id)\n",
    "    ids_ranges = [id_list[x:x+500] for x in range(0, len(id_list), 500)]\n",
    "    ids_ranges_tuples = [tuple(sublist) for sublist in ids_ranges]\n",
    "\n",
    "    result_df = pd.DataFrame()\n",
    "    try:\n",
    "        sqlalchemy_engine=\"oracle+cx_oracle://\"+username+\":\"+password+\"@\"+dbhostname+\"/?service_name=\"+service_name\n",
    "        engine = sqlalchemy.create_engine(sqlalchemy_engine, arraysize=1000)\n",
    "\n",
    "        for ids in ids_ranges_tuples:\n",
    "            query = f\"\"\"SELECT ID_DMC, CIRCUIT_NR, \n",
    "                    MAX(ASSIGMENT) AS ASSIGMENT, \n",
    "                    MAX(FLOW) AS FLOW, \n",
    "                    MAX(SET_POINT) AS SET_POINT,\n",
    "                    MAX(START_DELAY) AS START_DELAY,\n",
    "                    MAX(TEMP) AS TEMP,\n",
    "                    MAX(WORKING_MODE) AS WORKING_MODE\n",
    "                FROM Z3DMC.ONI_CIRCUITS\n",
    "                WHERE ID_DMC IN {ids}\n",
    "                GROUP BY ID_DMC, CIRCUIT_NR\n",
    "                ORDER BY ID_DMC\n",
    "                \"\"\"\n",
    "    \n",
    "            df = pd.read_sql(query, engine)\n",
    "            result_df = pd.concat([result_df, df], ignore_index=True)\n",
    "\n",
    "            \n",
    "    except SQLAlchemyError as e:\n",
    "        print(e)\n",
    "\n",
    "    data.update({'ONI_CIRCUITS': result_df})\n",
    "    \n",
    "    return data\n",
    "\n",
    "def combine_into_one_table(data):\n",
    "    data['ONI_CIRCUITS'].drop(columns = ['assigment', 'working_mode', 'set_point'], inplace = True)\n",
    "    oni_circuits = data['ONI_CIRCUITS'].pivot(index='id_dmc', columns='circuit_nr', values=['flow', 'start_delay', 'temp'])\n",
    "    oni_circuits.columns = oni_circuits.columns.map('{0[0]}_{0[1]}'.format) \n",
    "    oni_circuits.reset_index(inplace=True)\n",
    "    final_table = data['MEB_DGM'].copy()\n",
    "    final_table = final_table.merge(oni_circuits, left_on='id', right_on='id_dmc', how='inner')\n",
    "\n",
    "    return final_table\n",
    "\n",
    "# Save value to a text file\n",
    "def save_id_to_file(value, filename='pipeline_files/id.txt'):\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(str(value))\n",
    "\n",
    "# Read value from a text file\n",
    "def read_id_from_file(filename='pipeline_files/id.txt'):\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            return file.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def distribution_of_probability_plot_pipe(predictions, y_test, name_, show_figure=False):\n",
    "    \n",
    "    predictions = predictions.reshape(-1, 1)\n",
    "    pred_class_test = {'ok': predictions[y_test == 0],\n",
    "                       'nok': predictions[y_test == 1]}\n",
    "\n",
    "    width = 0.35  # Width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    for i, (key, pred_probability) in enumerate(pred_class_test.items()):\n",
    "        bins = np.arange(0, 1.1, 0.1)\n",
    "        hist, edges = np.histogram(pred_probability, bins=bins, density=True)\n",
    "        x_ticks_labels = [f'{i:.1f} - {(i + 0.1):.1f}' for i in edges[:-1]]\n",
    "\n",
    "        bar_color = 'red' if key == 'nok' else 'green'\n",
    "        bar_positions = np.arange(len(x_ticks_labels)) + i * width\n",
    "\n",
    "        ax.bar(bar_positions, hist * 10, width, alpha=0.7, label=key, color=bar_color)\n",
    "\n",
    "        # Add value labels on top of each bar (rotated vertically)\n",
    "        for x, value in zip(bar_positions, hist * 10):\n",
    "            ax.text(x + width / 2 - 0.1, value + 1, f'{value:.2f}%', ha='center', va='bottom', rotation='vertical')\n",
    "\n",
    "    ax.set_xlabel('Probability Range')\n",
    "    ax.set_ylabel('Percentage')\n",
    "    ax.set_title(f'Distribution {name_}')\n",
    "    ax.set_xticks(bar_positions - width / 2)\n",
    "    ax.set_xticklabels(x_ticks_labels, fontsize=8)\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 75)  # Set y-axis limit to 100%\n",
    "    \n",
    "    if show_figure:\n",
    "        plt.show()\n",
    "\n",
    "    return fig\n",
    "\n",
    "def stats_about_predictions(predictions_, y_true_, y_classes_pred):\n",
    "\n",
    "    print(f\"Number of checked parts in this part: {len(predictions_)}\")\n",
    "    print(f\"Number of NOK parts: {np.sum(y_classes_pred == 1)}\")\n",
    "    print(f\"Percent of NOK parts in this part: {np.sum(y_classes_pred == 1) / len(predictions_)}\")\n",
    "\n",
    "\n",
    "def predict_status(model_, data, y_true, threshold = 0.925):\n",
    "\n",
    "    dmatrix = xgb.DMatrix(data.drop(columns = ['id','our_final_status', 'data_odlania', 'nr_dgm']))\n",
    "    predictions = model_.predict(dmatrix)\n",
    "    y_pred = np.where(predictions < threshold, 0, 1)\n",
    "    #print(y_pred)\n",
    "\n",
    "    stats_about_predictions(predictions, y_true, y_pred)\n",
    "    return y_pred, predictions\n",
    "\n",
    "def create_confusion_matrix_pipe(y_true, y_pred, name_):\n",
    "\n",
    "    cmat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.matshow(cmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "    for i in range(cmat.shape[0]):\n",
    "        for j in range(cmat.shape[1]):\n",
    "            ax.text(x=j, y=i,s=cmat[i, j], va='center', ha='center', size='xx-large')\n",
    "    \n",
    "    ax.set_xlabel('Predictions', fontsize=18)\n",
    "    ax.set_ylabel('Actuals', fontsize=18)\n",
    "    ax.set_title(f'Confusion Matrix {name_}', fontsize=18)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data from last id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgm, id_max = read_last_meb_dgm(1474000)          # 1474000    1494449 #1497425"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgm = check_if_meb_base(dgm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgm_oni = read_oni(dgm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgm_oni['ONI_CIRCUITS'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tab = combine_into_one_table(dgm_oni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_dgm9 = final_tab[final_tab['nr_dgm']==9]\n",
    "fin_dgm10 = final_tab[final_tab['nr_dgm']==10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_needed = pd.read_csv('./pipeline_files/column_names.csv', header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_needed = list(from_october_new_status.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = final_tab.columns.difference(columns_needed)\n",
    "final_tab = final_tab.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the XGBoost model\n",
    "model = xgb.Booster(model_file=r'C:\\Users\\DLXPMX8\\Desktop\\Projekt_AI\\meb_process_data_analysis\\src\\final_model\\model\\model.xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmatrix = xgb.DMatrix(final_tab)\n",
    "predictions = model.predict(dmatrix)\n",
    "y_pred = np.where(predictions < 0.90, 0, 1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_pred == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Detale zbadane: {len(y_pred)}')\n",
    "print(f\"Detale NOK: {np.sum(y_pred == 1)}\")\n",
    "print(f\"Procent detali NOK: {np.sum(y_pred == 1) / len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new_status = xgb.Booster(model_file=r'C:\\Users\\DLXPMX8\\Desktop\\Projekt_AI\\meb_process_data_analysis\\src\\mlruns/945490748662708885/6736d82660a54376a1a6f211c8fc90a6/artifacts/model/model.xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmatrix = xgb.DMatrix(final_tab.drop(columns=['id', 'nr_dgm']))\n",
    "predictions = model_new_status.predict(dmatrix)\n",
    "y_pred = np.where(predictions < 0.90, 0, 1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Detale zbadane: {len(y_pred)}')\n",
    "print(f\"Detale NOK: {np.sum(y_pred == 1)}\")\n",
    "print(f\"Procent detali NOK: {np.sum(y_pred == 1) / len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From October predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_dgm9 = from_october[from_october['nr_dgm']==9]\n",
    "fin_dgm10 = from_october[from_october['nr_dgm']==10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data without nok from dgm controlle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_table_with_all_columns['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ids = whole_table_with_all_columns.loc[whole_table_with_all_columns['status'] != 1, 'id'].tolist()\n",
    "\n",
    "oryginal_len = from_october.shape[0]\n",
    "from_october_without_dgm_nok = from_october[~from_october['id'].isin(filtered_ids)]\n",
    "\n",
    "print(f\"Number of rows deleted: {oryginal_len - from_october_without_dgm_nok.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dgm9_and_10 = xgb.Booster(model_file=r'C:\\Users\\DLXPMX8\\Desktop\\Projekt_AI\\meb_process_data_analysis\\src\\final_model\\model\\model.xgb')\n",
    "model_new_status = xgb.Booster(model_file=r'C:\\Users\\DLXPMX8\\Desktop\\Projekt_AI\\meb_process_data_analysis\\src\\mlruns/945490748662708885/6736d82660a54376a1a6f211c8fc90a6/artifacts/model/model.xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_dgm9 = from_october[from_october['nr_dgm']==9]\n",
    "fin_dgm10 = from_october[from_october['nr_dgm']==10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dgm9 = fin_dgm9['our_final_status']\n",
    "y_dgm10 = fin_dgm10['our_final_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_october = from_october['our_final_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_from_october_without_dgm_nok = from_october_without_dgm_nok['our_final_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_from_october_new_status = from_october_new_status['our_final_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_9_10_model_9_10 = predict_status(model_dgm9_and_10, from_october, y_october, threshold= 0.95)\n",
    "y_pred_9model_9_10 = predict_status(model, fin_dgm9, y_dgm9)\n",
    "# predict_status(model, fin_dgm10, y_dgm10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_9_10_model_without_dgm = predict_status(model_dgm9_and_10, from_october_without_dgm_nok, y_from_october_without_dgm_nok, threshold= 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_new_status = predict_status(model_new_status, from_october_new_status, y_from_october_new_status,threshold= 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_9 = create_confusion_matrix(y_dgm9, y_pred_9model_9_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_910 = create_confusion_matrix(y_october, y_pred_9_10_model_9_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_without_nok_dgm = create_confusion_matrix(y_from_october_without_dgm_nok, y_pred_9_10_model_without_dgm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_new_status = create_confusion_matrix(y_from_october_new_status, y_pred_new_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models for dgm9 and dgm10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dgm9 = xgb.Booster(model_file=r'c:\\Users\\DLXPMX8\\Desktop\\Projekt_AI\\meb_process_data_analysis\\src\\mlruns/833265486894331728/127032651b42435ea75d46b13e60c537/artifacts/model/model.xgb')\n",
    "model_dgm10 = xgb.Booster(model_file=r'c:\\Users\\DLXPMX8\\Desktop\\Projekt_AI\\meb_process_data_analysis\\src\\mlruns/434245836703521692/50856305a5a942f5ac6526184e71a85a/artifacts/model/model.xgb')\n",
    "model_dgm9_and_10 = xgb.Booster(model_file=r'C:\\Users\\DLXPMX8\\Desktop\\Projekt_AI\\meb_process_data_analysis\\src\\final_model\\model\\model.xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_october_dgm9 = load_csv('test_dgm9_9_from_october.csv')\n",
    "from_october_dgm10 = load_csv('test_dgm10_10_from_october.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dgm9 = from_october_dgm9['our_final_status']\n",
    "y_dgm10 = from_october_dgm10['our_final_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_october_dgm9['data_odlania'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DGM9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_status(model, from_october, y_october)\n",
    "y_pred_dgm9 = predict_status(model_dgm9, from_october_dgm9, y_dgm9, threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dgm9_from_model_9_10 = predict_status(model_dgm9_and_10, from_october_dgm9, y_dgm9, threshold=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_dgm9 = create_confusion_matrix(y_dgm9, y_pred_dgm9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_dgm9_from_model_9_10 = create_confusion_matrix(y_dgm9, y_pred_dgm9_from_model_9_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DGM10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dgm10 = predict_status(model_dgm10, from_october_dgm10, y_dgm10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dgm10_from_model_9_10 = predict_status(model_dgm9_and_10, from_october_dgm10, y_dgm10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_dgm10 = create_confusion_matrix(y_dgm10, y_pred_dgm10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_dgm10_from_model_9_10 = create_confusion_matrix(y_dgm10, y_pred_dgm10_from_model_9_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fin_dgm9.shape)\n",
    "print(from_october_dgm9.shape)\n",
    "print(fin_dgm10.shape)\n",
    "print(from_october_dgm10.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rozłożenie detali NOK w czasie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_final_table_dgm8(data_tmp):\n",
    "\n",
    "    data = data_tmp.copy()\n",
    "    # usuwanie znaków białych z DMC[MEB_DGM] i DMC_CASTING[MEB_DMC]\n",
    "    data['MEB_DMC'].dmc_casting = data['MEB_DMC']['dmc_casting'].str.strip()\n",
    "    data['MEB_DGM'].dmc = data['MEB_DGM']['dmc'].str.strip()\n",
    "\n",
    "    # usuwanie z meb_dmc wierszy z 'WORKPIECE NIO' w kodzie DMC\n",
    "    data['MEB_DMC'] = data['MEB_DMC'][~data['MEB_DMC']['dmc'].str.contains('WORKPIECE', case=False, na=False)]\n",
    "\n",
    "    # wybieranie rekordów dla MEB+ \n",
    "    data['MEB_DGM'] = data['MEB_DGM'][(data['MEB_DGM']['nr_dgm'].between(8, 8)) & (data['MEB_DGM']['dmc'].apply(lambda x: len(str(x)) == 21))]\n",
    "    # usunięcie anomalii z MEB_DMC\n",
    "    data['MEB_DMC'] = data['MEB_DMC'][data['MEB_DMC']['dmc'].str[:3] == '0MH']\n",
    "\n",
    "    # łączę tabele MEB_KO i MEB_KO_DGM z tabelami MEB_KO_STREFA/RODZAJ\n",
    "    data['MEB_KO'] = data['MEB_KO'].merge(data['MEB_KO_STREFA'], left_on='nok_strefa', right_on='indeks', how='inner')\n",
    "    data['MEB_KO'].drop(columns=['indeks'], inplace=True)\n",
    "    data['MEB_KO'] = data['MEB_KO'].merge(data['MEB_KO_RODZAJ'], left_on='nok_rodzaj', right_on='indeks', how='inner')\n",
    "    data['MEB_KO'].drop(columns=['indeks'], inplace=True)\n",
    "    data['MEB_KO_DGM'] = data['MEB_KO_DGM'].merge(data['MEB_KO_STREFA'], left_on='nok_strefa', right_on='indeks', how='inner')\n",
    "    data['MEB_KO_DGM'].drop(columns=['indeks'], inplace=True)\n",
    "    data['MEB_KO_DGM'] = data['MEB_KO_DGM'].merge(data['MEB_KO_RODZAJ'], left_on='nok_rodzaj', right_on='indeks', how='inner')\n",
    "    data['MEB_KO_DGM'].drop(columns=['indeks'], inplace=True)\n",
    "\n",
    "    # łączę tabelę MEB_DMC z tabelą MEB_KO\n",
    "    data['MEB_DMC'] = data['MEB_DMC'].merge(data['MEB_KO'], on='id_dmc', how='left')\n",
    "    data['MEB_DMC'].drop(columns=['rn'], inplace=True)\n",
    "\n",
    "    # łączę tabelę MEB_DMC z tabelą MEB_GROB\n",
    "    data['MEB_DMC'] = data['MEB_DMC'].merge(data['MEB_GROB'], on='id_dmc', how='left')\n",
    "    data['MEB_DMC'].drop(columns=['rn'], inplace=True)\n",
    "\n",
    "    # łączę tabelę MEB_DMC z tabelą MEB_KS\n",
    "    data['MEB_DMC'] = data['MEB_DMC'].merge(data['MEB_KS'], on='id_dmc', how='left')\n",
    "    data['MEB_DMC'].drop(columns=['rn'], inplace=True)\n",
    "\n",
    "\n",
    "    final_table = data['MEB_DGM'].copy()\n",
    "    final_table.drop(columns=['rn'], inplace=True)\n",
    "\n",
    "    # łączę tabelę MEB_DGM z tabelą MEB_KO_DGM\n",
    "    final_table = final_table.merge(data['MEB_KO_DGM'], left_on='id', right_on='id_dmc', how='left')\n",
    "    final_table.drop(columns=['rn'], inplace=True)\n",
    "\n",
    "    # łączę z tabelą MEB_DGM\n",
    "    final_table.rename(columns={'id_dmc_x': 'id_dmc'}, inplace=True)\n",
    "\n",
    "    # łączę tabelę MEB_DMC z ONI_CIRCUITS\n",
    "    final_table = final_table.merge(data['MEB_DMC'], left_on='dmc', right_on='dmc_casting', how='left', suffixes=('_DGM', '_DMC'))\n",
    "\n",
    "    final_table.drop(columns=['nok_strefa_DGM', 'nok_rodzaj_DGM', 'status_ko_DGM', 'kod_pola_DGM', 'rodzaj_uszkodzenia_DGM'], inplace=True)\n",
    "    final_table.rename(columns={'nok_strefa_DMC': 'nok_strefa', 'nok_rodzaj_DMC': 'nok_rodzaj', \n",
    "                                'status_ko_DMC': 'status_ko', 'kod_pola_DMC': 'kod_pola', \n",
    "                                'rodzaj_uszkodzenia_DMC': 'rodzaj_uszkodzenia'}, inplace=True)\n",
    "                                \n",
    "    final_table.drop(index=final_table[(final_table['dmc_DGM'].duplicated(keep=False)) & (~final_table['dmc_casting'].isna())].index, inplace=True)\n",
    "    final_table.drop(columns = ['part_status'], inplace = True)\n",
    "\n",
    "    return final_table\n",
    "\n",
    "def create_final_status_dgm8(final_table_tmp):\n",
    "    # statusy dmc 2 zostały całkowicie wywalone (jest ich ok. 450)\n",
    "    # co do statusu szczelności to czasami na to wpływ ma porowatość wynikająca z odlewania,\n",
    "    # jednak jest dużo błędów wynikających z obróbki czy zepsutej uszczelki\n",
    "\n",
    "    final_table = final_table_tmp.copy()\n",
    "    final_table = final_table[~final_table['status'].isin(['4', '5', '7', '8', '10', '11'])]\n",
    "    final_table['status'] = final_table['status'].replace(['3', '14'], '2')\n",
    "    final_table = final_table.loc[~final_table['status_ko'].isin([0, 106])]\n",
    "    final_table = final_table.loc[~final_table['statusszczelnosc'].isin([0, 3])]\n",
    "    final_table = final_table.loc[~final_table['statusdmc'].isin([0,2])]\n",
    "\n",
    "    final_table['our_final_status'] = final_table.apply(lambda row: max(int(row['status']), row['status_ko'], row['statusszczelnosc'], row['statusdmc']), axis=1)\n",
    "    print(final_table['our_final_status'].value_counts())\n",
    "    final_table.drop(columns=['status', 'status_ko', 'statusszczelnosc', 'statusdmc', \n",
    "                              'part_type', 'nrprogramu', 'id_dmc_DGM', \n",
    "                              'id_dmc_DGM', 'dmc_DGM', 'product_id', 'line_id', \n",
    "                              'dmc_DMC', 'dmc_casting', 'nok_strefa', 'nok_rodzaj'], inplace=True)  # 'nr_dgm' na razie nie kasuje bo testuje dane - JR 25.09\n",
    "\n",
    "    return final_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dgm8 = read_data_from_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dgm8 = combine_final_table_dgm8(data_dgm8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dgm8 = create_final_status_dgm8(final_dgm8)\n",
    "final_dgm8.drop(final_dgm8[final_dgm8['our_final_status'] == 104].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dgm8 = categorize_data(final_dgm8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dgm8 = final_dgm8[(final_dgm8['data_odlania'].dt.month >= 10) & (final_dgm8['data_odlania'].dt.year >= 2023)]\n",
    "train_dgm8 = final_dgm8.iloc[:-int(test_dgm8.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = train_dgm8.columns.difference(columns_needed)\n",
    "dgm8_train = train_dgm8.drop(columns=columns_to_drop)\n",
    "dgm8_test = test_dgm8.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_samples = dgm8_train[dgm8_train['our_final_status']==0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = split_data(dgm8_train, samples= int(ok_samples/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_models.xg_boost import *\n",
    "\n",
    "clf = xgb_model(*ml_data.values(), run_name_=\"nn_dgm8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dgm8 = xgb.Booster(model_file=r\"c:/Users/DLXPMX8/Desktop/Projekt_AI/meb_process_data_analysis/src/mlruns/558158636042431628/335d53680b064a488c0e6c10dd0cd575/artifacts/model/model.xgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dgm8 = dgm8_test['our_final_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmatrix = xgb.DMatrix(dgm8_test.drop(columns = ['our_final_status']))\n",
    "predictions = model_dgm8.predict(dmatrix)\n",
    "y_dgm8_pred = np.where(predictions < 0.9, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = create_confusion_matrix(y_dgm8, y_dgm8_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINITYWNY TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mflow_model_names = [\"dgm9_9_v1_2021\", \"dgm9_9_v1_2023\", \"dgm9_9_v2_2021\", \"dgm9_9_v2_2023\",\n",
    "                \"dgm9_10_v1_2021\", \"dgm9_10_v1_2023\", \"dgm9_10_v2_2021\", \"dgm9_10_v2_2023\",\n",
    "                \"dgm10_10_v1_2021\", \"dgm10_10_v1_2023\", \"dgm10_10_v2_2021\", \"dgm10_10_v2_2023\"]\n",
    "file_names = [\"test_9_9_from_october_v1_2021\", \"test_9_9_from_october_v1_2023\", \"test_9_9_from_october_v2_2021\", \"test_9_9_from_october_v2_2023\",\n",
    "              \"test_9_10_from_october_v1_2021\", \"test_9_10_from_october_v1_2023\", \"test_9_10_from_october_v2_2021\", \"test_9_10_from_october_v2_2023\",\n",
    "              \"test_10_10_from_october_v1_2021\", \"test_10_10_from_october_v1_2023\", \"test_10_10_from_october_v2_2021\", \"test_10_10_from_october_v2_2023\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Żeby użyć tej funkcji, wystarczy odpalić w mlflow jeden z runów, który chcemy znaleźć, \n",
    "#skopiować ścieżkę do modelu i wziąć z niej kawałek ścieżki i wkleic nizej w kodzie, przed /{run_id} \n",
    "#file://c:\\Users\\DLXPMX8\\Desktop\\Projekt_AI\\meb_process_data_analysis\\src\\mlruns/398223559176573127/9885772033934fb39601562d4e92091d/artifacts/model/model.xgb\n",
    "# 398223559176573127 ^\n",
    "# Jak i zmienic experiment_name\n",
    "experiment_name = \"new_status_v4\"\n",
    "model_dict = {}\n",
    "\n",
    "for run_name, file_name in zip(mflow_model_names, file_names):\n",
    "    runs = mlflow.search_runs(experiment_ids=mlflow.get_experiment_by_name(experiment_name).experiment_id, filter_string=f\"tags.mlflow.runName = 'xgboost_{run_name}'\")\n",
    "    if not runs.empty:\n",
    "        run_id = runs.iloc[0]['run_id']\n",
    "        print(f\"Run ID for '{run_name}': {run_id}\")\n",
    "        model_dict[file_name] = {'model' : xgb.Booster(model_file=rf\"c:\\Users\\DLXPMX8\\Desktop\\Projekt_AI\\meb_process_data_analysis\\src\\mlruns/398223559176573127/{run_id}/artifacts/model/model.xgb\")}\n",
    "        model_dict[file_name]['data'] = load_csv(f\"{file_name}.csv\")\n",
    "        model_dict[file_name]['y_true'] = model_dict[file_name]['data'][\"our_final_status\"]\n",
    "\n",
    "    else:\n",
    "        print(f\"No run found with name '{run_name}' in experiment '{experiment_name}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "models_paths = [r\"C:\\Users\\DLXPMX8\\Desktop\\Projekt_AI\\meb_process_data_analysis\\src\\mlruns/945490748662708885/19f714728495414fa94f5a819ce96e71/artifacts/model/model.xgb\",\n",
    "                r\"C:\\Users\\DLXPMX8\\Desktop\\Projekt_AI\\meb_process_data_analysis\\src\\mlruns/945490748662708885/401de82b083248c4888ecedacc65036f/artifacts/model/model.xgb\",\n",
    "                r\"C:\\Users\\DLXPMX8\\Desktop\\Projekt_AI\\meb_process_data_analysis\\src\\mlruns/945490748662708885/8c567d87306740169e4c5a0ade3ae401/artifacts/model/model.xgb\",\n",
    "                r\"C:\\Users\\DLXPMX8\\Desktop\\Projekt_AI\\meb_process_data_analysis\\src\\mlruns/945490748662708885/4535bb5bb6ca40acb8b07aaa6be1389f/artifacts/model/model.xgb\",\n",
    "                r\"C:\\Users\\DLXPMX8\\Desktop\\Projekt_AI\\meb_process_data_analysis\\src\\mlruns/945490748662708885/ec11baf0875b49b8b3332444a9170282/artifacts/model/model.xgb\",\n",
    "                r\"C:\\Users\\DLXPMX8\\Desktop\\Projekt_AI\\meb_process_data_analysis\\src\\mlruns/945490748662708885/fdd8693db68d4655a5f53ae3e69a7d97/artifacts/model/model.xgb\",\n",
    "                r\"C:\\Users\\DLXPMX8\\Desktop\\Projekt_AI\\meb_process_data_analysis\\src\\mlruns/945490748662708885/e6cfc973639843298ecca2ec92adf8ee/artifacts/model/model.xgb\",\n",
    "                r\"C:\\Users\\DLXPMX8\\Desktop\\Projekt_AI\\meb_process_data_analysis\\src\\mlruns/945490748662708885/d01eb5eb71f64bcd8c330be393de77c8/artifacts/model/model.xgb\",\n",
    "                r\"C:\\Users\\DLXPMX8\\Desktop\\Projekt_AI\\meb_process_data_analysis\\src\\mlruns/945490748662708885/cbe6ae5bdf724a06b89a1f15fcdb6f18/artifacts/model/model.xgb\",\n",
    "                r\"C:\\Users\\DLXPMX8\\Desktop\\Projekt_AI\\meb_process_data_analysis\\src\\mlruns/945490748662708885/f017d7d6a55949459945e044ac27fceb/artifacts/model/model.xgb\",\n",
    "                r\"C:\\Users\\DLXPMX8\\Desktop\\Projekt_AI\\meb_process_data_analysis\\src\\mlruns/945490748662708885/986b39fe62f84cf28cc42271d2dd5223/artifacts/model/model.xgb\",\n",
    "                r\"C:\\Users\\DLXPMX8\\Desktop\\Projekt_AI\\meb_process_data_analysis\\src\\mlruns/945490748662708885/27c52aa84238478fb9400d54873c8d78/artifacts/model/model.xgb\"]\n",
    "\n",
    "\n",
    "\n",
    "for file_name, model_path in zip(file_names, models_paths):\n",
    "    model_dict[file_name] = {'model' : xgb.Booster(model_file=model_path)}\n",
    "    model_dict[file_name]['data'] = load_csv(f\"{file_name}.csv\")\n",
    "    model_dict[file_name]['y_true'] = model_dict[file_name]['data'][\"our_final_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name, model_ in model_dict.items():\n",
    "    print(\"###########################################################\")\n",
    "    print(f\"MODEL: {file_name}\")\n",
    "    model_['y_pred'], model_['clean_prob'] = predict_status(model_['model'], model_['data'], model_[\"y_true\"], threshold= 0.9)\n",
    "    print(\"###########################################################\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name, model_ in model_dict.items():\n",
    "    print(\"###########################################################\")\n",
    "    print(f\"MODEL: {file_name}\")\n",
    "    model_['dist_plot'] = distribution_of_probability_plot_pipe(model_['clean_prob'], model_['y_true'], file_name, True)\n",
    "    print(\"###########################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name, model_ in model_dict.items():\n",
    "    print(\"###########################################################\")\n",
    "    print(f\"MODEL: {file_name}\")\n",
    "    model_['conf_matrix'] = create_confusion_matrix_pipe(model_['y_true'], model_['y_pred'], file_name)\n",
    "    print(\"###########################################################\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name, model_ in model_dict.items():\n",
    "    print(file_name)\n",
    "    print(model_['data'].shape)\n",
    "    print(model_['y_true'].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DO THESE STATUSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_db = read_data_from_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_final_status_test(final_table):\n",
    "    \n",
    "    final_table['status'] = final_table['status'].astype(int)\n",
    "    final_table['nok_rodzaj'] = final_table['nok_rodzaj'].fillna(0)\n",
    "    #final_table['nok_rodzaj'] = final_table['nok_rodzaj'].astype(int)\n",
    "    \n",
    "    print(final_table['status'].value_counts())\n",
    "    final_table = final_table[final_table['status'].isin([0,1,3,14])]\n",
    "    final_table['status'] = final_table['status'].replace([3, 14], 2)\n",
    "\n",
    "    print('####################')\n",
    "    print('status counts')\n",
    "    print(final_table['status'].value_counts())\n",
    "\n",
    "    final_table = final_table.loc[~final_table['status_ko'].isin([0, 106])] # KO\n",
    "    final_table = final_table.loc[~final_table['statusszczelnosc'].isin([0, 3])]\n",
    "    final_table = final_table.loc[~final_table['statusdmc'].isin([0,2])]\n",
    "    print(f'Number of NOK parts on DGM: {final_table[\"status\"].isin([2]).sum()}')\n",
    "    print(f'Number of NOK parts of DGM on KO: {final_table[\"nok_rodzaj\"].isin([102, 201, 103, 101]).sum()}')\n",
    "\n",
    "    print('####################')\n",
    "    print('nok_rodzaj counts')\n",
    "    print(final_table['nok_rodzaj'].value_counts())\n",
    "\n",
    "    final_table = final_table.loc[final_table['nok_rodzaj'].isin([0, 102, 201, 103, 101])]\n",
    "    final_table['nok_rodzaj'] = final_table['nok_rodzaj'].replace([102, 201, 103, 101], 2)\n",
    "    final_table['nok_rodzaj'] = final_table['nok_rodzaj'].replace([0], 1)\n",
    "\n",
    "    print('####################')\n",
    "    print('nok_rodzaj counts')\n",
    "    print(final_table['nok_rodzaj'].value_counts())\n",
    "\n",
    "    print('####################')\n",
    "    print('status counts 2')\n",
    "    print(final_table['status'].value_counts())\n",
    "    \n",
    "    final_table['our_final_status'] = final_table.apply(lambda row: max(int(row['status']), row['nok_rodzaj'], row['statusszczelnosc'], row['statusdmc']), axis=1)\n",
    "    #final_table['our_final_status'] = final_table[['status', 'nok_rodzaj', 'statusszczelnosc', 'statusdmc']].apply(lambda row: max(int(row['status']), row['nok_rodzaj'], row['statusszczelnosc'], row['statusdmc']), axis=1)\n",
    "    print(f\"Final number of NOK parts: {final_table['our_final_status'].value_counts()}\")\n",
    "    final_table.drop(columns=['status', 'status_ko', 'statusszczelnosc', 'statusdmc', \n",
    "                              'part_type', 'nrprogramu', 'id_dmc_DGM', \n",
    "                              'id_dmc_DGM', 'dmc_DGM', 'product_id', 'line_id', \n",
    "                              'dmc_DMC', 'dmc_casting', 'nok_strefa', 'nok_rodzaj'], inplace=True)  # 'nr_dgm' na razie nie kasuje bo testuje dane - JR 25.09\n",
    "\n",
    "    return final_table\n",
    "\n",
    "def create_final_status_2_test(final_table):\n",
    "\n",
    "    final_table = final_table.loc[final_table['status'].isin(['1'])]\n",
    "    final_table = final_table.loc[~final_table['status_ko'].isin([0, 106])] # 'status_ko_DMC'\n",
    "    final_table = final_table.loc[~final_table['statusszczelnosc'].isin([0, 3])]\n",
    "    final_table = final_table.loc[~final_table['statusdmc'].isin([0,2])]\n",
    "    print(f'Number of NOK parts on DGM: {final_table[\"status\"].isin([\"2\"]).sum()}')\n",
    "    print(f'Number of NOK parts of DGM on KO: {final_table[\"nok_rodzaj\"].isin([102, 201, 103, 101]).sum()}')\n",
    "    final_table = final_table.loc[final_table['nok_rodzaj'].isin([0, 102, 201, 103, 101])]\n",
    "    final_table['nok_rodzaj'] = final_table['nok_rodzaj'].replace([102, 201, 103, 101], 2)\n",
    "    final_table['nok_rodzaj'] = final_table['nok_rodzaj'].replace([0], 1)\n",
    "    final_table['our_final_status'] = final_table.apply(lambda row: max(row['nok_rodzaj'], row['statusszczelnosc'], row['statusdmc']), axis=1)\n",
    "    print(f'Final number of NOK parts: {final_table[\"our_final_status\"].value_counts()}')\n",
    "    final_table.drop(columns=['status', 'status_ko', 'statusszczelnosc', 'statusdmc', \n",
    "                              'part_type', 'nrprogramu', 'id_dmc_DGM', \n",
    "                              'id_dmc_DGM', 'dmc_DGM', 'product_id', 'line_id', \n",
    "                              'dmc_DMC', 'dmc_casting', 'nok_strefa', 'nok_rodzaj'], inplace=True)  # 'nr_dgm' na razie nie kasuje bo testuje dane - JR 25.09\n",
    "\n",
    "    return final_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_set_for_dgm_test(all_data, version_of_status, from_dgm=8, to_dgm=10, start_year= 2021):\n",
    "\n",
    "    print(f\"Making set for dgm {from_dgm} to {to_dgm}, status version: {version_of_status}, from year: {start_year}\")\n",
    "    dgm_all = copy.deepcopy(all_data)\n",
    "    dgm_table = combine_final_table(dgm_all, dgm_smallest=from_dgm, dgm_biggest=to_dgm)\n",
    "    \n",
    "    dgm_table['data_odlania'] = pd.to_datetime(dgm_table['data_odlania'])\n",
    "    if start_year > 2021:\n",
    "        dgm_table = dgm_table[dgm_table['data_odlania'].dt.year >= start_year]\n",
    "\n",
    "    print('Create final status')\n",
    "    if version_of_status == '1':\n",
    "        print(\"VERSION 1\")\n",
    "        dgm_table = create_final_status_test(dgm_table)\n",
    "    elif version_of_status == '2': \n",
    "        print(\"VERSION 2\")\n",
    "        dgm_table = create_final_status_2_test(dgm_table)\n",
    "\n",
    "    print('Drop columns not used in ml')\n",
    "    dgm_table= drop_columns_not_used_in_ml(dgm_table)\n",
    "    print('Categorize data')\n",
    "    dgm = categorize_data(dgm_table)\n",
    "\n",
    "    print(\"Make test set from October\")\n",
    "    filtered_data_dgm = dgm[(dgm['data_odlania'].dt.month >= 10) & (dgm['data_odlania'].dt.year >= 2023)]\n",
    "    dgm= dgm.iloc[:-int(filtered_data_dgm.shape[0])]\n",
    "\n",
    "    dgm.drop(columns=['data_odlania','nr_dgm', 'id'], inplace = True)\n",
    "\n",
    "    dgm, high_corr_features_dgm = drop_columns_with_too_much_corr(dgm)\n",
    "    filtered_data_dgm = filtered_data_dgm.drop(columns= high_corr_features_dgm)\n",
    "\n",
    "    save_df_to_csv(dgm, f'final_table_{from_dgm}_{to_dgm}_v{version_of_status}_{start_year}.csv')\n",
    "    save_df_to_csv(filtered_data_dgm, f'test_{from_dgm}_{to_dgm}_from_october_v{version_of_status}_{start_year}.csv')\n",
    "\n",
    "    ml_data_dgm = split_data(dgm, samples=(dgm['our_final_status'] == 1).sum() * 2)\n",
    "    normalize_and_save_to_csv(ml_data_dgm, file_name_=f'dgm{from_dgm}_{to_dgm}_v{version_of_status}_{start_year}')\n",
    "\n",
    "    return filtered_data_dgm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol = copy.deepcopy(data_db)\n",
    "lol_table = combine_final_table(lol, dgm_smallest=9, dgm_biggest=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol_table['status'] = lol_table['status'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lol_table['status'].dtype)\n",
    "print(lol_table['nok_rodzaj'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
